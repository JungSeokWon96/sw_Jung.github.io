{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention : Neural machine translation by jointly learning to align and translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('https://youtu.be/vV5LOseLw5E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model structer](https://velog.velcdn.com/images%2Fxuio%2Fpost%2Fe3d72f7b-882e-4ae9-bf06-6866b1d74be7%2Fimage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존의 Translation 모델들은 Encoder의 경우, 입력문장을 고정길이 벡터러 변환신키고,decoder는 해당 벡터를 이용해서 변역 결과를 생성해 낸다. **이러한 러한 encoder-decoder 구조는 bottleneck 문제를 발생시킬 수 있다.** 이유로는 하나의 고정된 크기의 벡터에 모든 정보를 압축하려고 하니까 정보손실이 발생하기 때문이다. 이러한 문제는 문장이 길어질수록 심각하게 나타난다.\n",
    "\n",
    "해당 모델은 decoder에서 하나의 output을 내놓을 때마다, 입력 문장을 순차적으로 탐색해서 현재 생성하려는 부분과 가장 관련있는 영역을 적용시킨다. 그리고 이 관련 있는 부분은 생성 시점마다 변하게 된다. 최종적으로 encoder에서 생성한 context word 중 관련성이 크다고 판단되는 영역들과, decoder에서 이미 생성한 결과를 기반으로 다음 단어를 결과로 생성해낸다. 이러한 방식의 가장 큰 장점 중 하나는 입력 문장을 고정된 길이의 벡터로 표현하지 않아도 된다는 것이다. Decoder에서 연산을 진행하면서 encoder에서 생성한 context word를 계속해서 참조하기 때문에, 전체 문장의 정보를 하나의 벡터에 담으려고 하지 않아도 되고, 문장의 길이가 길어지더라도 성능을 유지할 수 있다.\n",
    "\n",
    "기존 seq2seq에서 마지막 hidden state의 1개만 가지고 context vector를 구축하는 것이 아닌 Attention에서는 모든 hidden state를 다 살려서 조합을 활용하여, 주어진 target word (input)과 가장 관련이 있을 것 같은 부분은 어디인지 찾아내는 네트워크를 추가하는 것으로 문제를 해결하고자 하였다.\n",
    "기존에 나온 단어들을 통해서만 hidden state를 구축하는 것이 아닌 앞으로 나올 단어에 대해서도 hidden state를 구축하여 거대한 context vector를 만들게 된다. 그리고 구축된 각각의 hidden state의 가중치 합을 만들어 context vector를 만드는 어텐션 메커니즘을 추가하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.4.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 19:22:22.038048: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-09-05 19:22:22.038078: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-05 19:22:25.693780: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-09-05 19:22:25.695535: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n",
      "2022-09-05 19:22:25.697180: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n",
      "2022-09-05 19:22:25.698820: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found\n",
      "2022-09-05 19:22:25.700497: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n",
      "2022-09-05 19:22:25.702164: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2022-09-05 19:22:25.702182: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (61.2.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 19:22:38.332234: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-09-05 19:22:38.332263: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-05 19:22:42.151560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-09-05 19:22:42.153037: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n",
      "2022-09-05 19:22:42.154458: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n",
      "2022-09-05 19:22:42.155854: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found\n",
      "2022-09-05 19:22:42.157275: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n",
      "2022-09-05 19:22:42.158646: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2022-09-05 19:22:42.158665: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from de-core-news-sm==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (61.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.21.5)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.9.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.11.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\jungsukwon\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jungsukwon\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리(Preprocessing)\n",
    "\n",
    "데이터 전처리는 앞의 Sequence to Sequence의 부분과 동일 함으로 따로 코멘트를 하지않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import de_core_news_sm\n",
    "import en_core_web_sm\n",
    "\n",
    "spacy_en = en_core_web_sm.load()\n",
    "spacy_de = de_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스 0: I\n",
      "인덱스 1: am\n",
      "인덱스 2: a\n",
      "인덱스 3: graduate\n",
      "인덱스 4: student\n",
      "인덱스 5: .\n"
     ]
    }
   ],
   "source": [
    "# 간단히 토큰화(tokenization) 기능 써보기\n",
    "tokenized = spacy_en.tokenizer(\"I am a graduate student.\")\n",
    "\n",
    "for i, token in enumerate(tokenized):\n",
    "    print(f\"인덱스 {i}: {token.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독일어(Deutsch) 문장을 토큰화 하는 함수 (순서를 뒤집지 않음)\n",
    "def tokenize_de(text):\n",
    "    return [token.text for token in spacy_de.tokenizer(text)]\n",
    "\n",
    "# 영어(English) 문장을 토큰화 하는 함수\n",
    "def tokenize_en(text):\n",
    "    return [token.text for token in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize_de, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True)\n",
    "TRG = Field(tokenize=tokenize_en, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터셋(training dataset) 크기: 29000개\n",
      "평가 데이터셋(validation dataset) 크기: 1014개\n",
      "테스트 데이터셋(testing dataset) 크기: 1000개\n"
     ]
    }
   ],
   "source": [
    "print(f\"학습 데이터셋(training dataset) 크기: {len(train_data.examples)}개\")\n",
    "print(f\"평가 데이터셋(validation dataset) 크기: {len(valid_data.examples)}개\")\n",
    "print(f\"테스트 데이터셋(testing dataset) 크기: {len(test_data.examples)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ein', 'mann', ',', 'der', 'mit', 'einer', 'tasse', 'kaffee', 'an', 'einem', 'urinal', 'steht', '.']\n",
      "['a', 'man', 'standing', 'at', 'a', 'urinal', 'with', 'a', 'coffee', 'cup', '.']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[30])['src'])\n",
    "print(vars(train_data.examples[30])['trg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(SRC): 7853\n",
      "len(TRG): 5893\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)\n",
    "\n",
    "print(f\"len(SRC): {len(SRC.vocab)}\")\n",
    "print(f\"len(TRG): {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4112\n",
      "1752\n"
     ]
    }
   ],
   "source": [
    "print(TRG.vocab.stoi[\"abcabc\"]) # 없는 단어: 0\n",
    "print(TRG.vocab.stoi[TRG.pad_token]) # 패딩(padding): 1\n",
    "print(TRG.vocab.stoi[\"<sos>\"]) # <sos>: 2\n",
    "print(TRG.vocab.stoi[\"<eos>\"]) # <eos>: 3\n",
    "print(TRG.vocab.stoi[\"hello\"])\n",
    "print(TRG.vocab.stoi[\"world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# 일반적인 데이터 로더(data loader)의 iterator와 유사하게 사용 가능\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 배치 크기: torch.Size([29, 128])\n",
      "인덱스 0: 2\n",
      "인덱스 1: 73\n",
      "인덱스 2: 4536\n",
      "인덱스 3: 8\n",
      "인덱스 4: 165\n",
      "인덱스 5: 9\n",
      "인덱스 6: 17\n",
      "인덱스 7: 19\n",
      "인덱스 8: 0\n",
      "인덱스 9: 0\n",
      "인덱스 10: 4\n",
      "인덱스 11: 3\n",
      "인덱스 12: 1\n",
      "인덱스 13: 1\n",
      "인덱스 14: 1\n",
      "인덱스 15: 1\n",
      "인덱스 16: 1\n",
      "인덱스 17: 1\n",
      "인덱스 18: 1\n",
      "인덱스 19: 1\n",
      "인덱스 20: 1\n",
      "인덱스 21: 1\n",
      "인덱스 22: 1\n",
      "인덱스 23: 1\n",
      "인덱스 24: 1\n",
      "인덱스 25: 1\n",
      "인덱스 26: 1\n",
      "인덱스 27: 1\n",
      "인덱스 28: 1\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "    src = batch.src\n",
    "    trg = batch.trg\n",
    "\n",
    "    print(f\"첫 번째 배치 크기: {src.shape}\")\n",
    "\n",
    "    # 현재 배치에 있는 하나의 문장에 포함된 정보 출력\n",
    "    for i in range(src.shape[0]):\n",
    "        print(f\"인덱스 {i}: {src[i][0].item()}\")\n",
    "\n",
    "    # 첫 번째 배치만 확인\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "- enc_hidden_dim: 인코더의 히든 상태(hidden state) 차원\n",
    "- dec_hidden_dim: 디코더의 히든 상태(hidden state) 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 인코더(Encoder) 아키텍처 정의\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, enc_hidden_dim, dec_hidden_dim, dropout_ratio):\n",
    "        super().__init__()\n",
    "\n",
    "        # 임베딩(embedding)은 원-핫 인코딩(one-hot encoding)을 특정 차원의 임베딩으로 매핑하는 레이어\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
    "\n",
    "        # 양방향(bidirectional) GRU 레이어\n",
    "        self.rnn = nn.GRU(embed_dim, enc_hidden_dim, bidirectional=True)\n",
    "\n",
    "        # FC 레이어\n",
    "        self.fc = nn.Linear(enc_hidden_dim * 2, dec_hidden_dim)\n",
    "\n",
    "        # 드롭아웃(dropout)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    # 인코더는 소스 문장을 입력으로 받아 문맥 벡터(context vector)를 반환        \n",
    "    def forward(self, src):\n",
    "        # src: [단어 개수, 배치 크기]: 각 단어의 인덱스(index) 정보\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded: [단어 개수, 배치 크기, 임베딩 차원]\n",
    "\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # outputs: [단어 개수, 배치 크기, 인코더 히든 차원 * 방향의 수]: 전체 단어의 출력 정보\n",
    "        # hidden: [레이어 개수 * 방향의 수, 배치 크기, 인코더 히든 차원]: 현재까지의 모든 단어의 정보\n",
    "\n",
    "        # hidden은 [forward_1, backward_1, forward_2, backward_2, ...] 형태로 구성\n",
    "        # 따라서 hidden[-2, :, :]은 forwards의 마지막 값\n",
    "        # 따라서 hidden[-1, :, :]은 backwards의 마지막 값\n",
    "        # 디코더(decoder)의 첫 번째 hidden (context) vector는 인코더의 마지막 hidden을 이용\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
    "\n",
    "        # outputs은 Attention 목적으로, hidden은 context vector 목적으로 사용\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# 어텐션(Attention) 아키텍처 정의\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hidden_dim, dec_hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attn = nn.Linear((enc_hidden_dim * 2) + dec_hidden_dim, dec_hidden_dim)\n",
    "        self.v = nn.Linear(dec_hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, enc_outputs):\n",
    "        # hidden: [배치 크기, 히든 차원]: 현재까지의 모든 단어의 정보\n",
    "        # enc_outputs: [단어 개수, 배치 크기, 인코더 히든 차원 * 방향의 수]: 전체 단어의 출력 정보\n",
    "        batch_size = enc_outputs.shape[1]\n",
    "        src_len = enc_outputs.shape[0]\n",
    "\n",
    "        # 현재 디코더의 히든 상태(hidden state)를 src_len만큼 반복\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        enc_outputs = enc_outputs.permute(1, 0, 2)\n",
    "        # hidden: [배치 크기, 단어 개수, 디코더 히든 차원]: 현재까지의 모든 단어의 정보\n",
    "        # enc_outputs: [배치 크기, 단어 개수, 인코더 히든 차원 * 방향의 수]: 전체 단어의 출력 정보\n",
    "\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, enc_outputs), dim=2)))\n",
    "        # energy: [배치 크기, 단어 개수, 디코더 히든 차원]\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        # attention: [배치 크기, 단어 개수]: 실제 각 단어에 대한 어텐선(attention) 값들\n",
    "\n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더(Decoder) 아키텍처 정의\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, enc_hidden_dim, dec_hidden_dim, dropout_ratio, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "\n",
    "        # 임베딩(embedding)은 원-핫 인코딩(one-hot encoding) 말고 특정 차원의 임베딩으로 매핑하는 레이어\n",
    "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
    "\n",
    "        # GRU 레이어\n",
    "        self.rnn = nn.GRU((enc_hidden_dim * 2) + embed_dim, dec_hidden_dim)\n",
    "\n",
    "        # FC 레이어\n",
    "        self.fc_out = nn.Linear((enc_hidden_dim * 2) + dec_hidden_dim + embed_dim, output_dim)\n",
    "        \n",
    "        # 드롭아웃(dropout)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    # 디코더는 현재까지 출력된 문장에 대한 정보를 입력으로 받아 타겟 문장을 반환     \n",
    "    def forward(self, input, hidden, enc_outputs):\n",
    "        # input: [배치 크기]: 단어의 개수는 항상 1개이도록 구현\n",
    "        # hidden: [배치 크기, 히든 차원]\n",
    "        # enc_outputs: [단어 개수, 배치 크기, 인코더 히든 차원 * 방향의 수]: 전체 단어의 출력 정보\n",
    "        input = input.unsqueeze(0)\n",
    "        # input: [단어 개수 = 1, 배치 크기]\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded: [단어 개수 = 1, 배치 크기, 임베딩 차원]\n",
    "\n",
    "        attention = self.attention(hidden, enc_outputs)\n",
    "        # attention: [배치 크기, 단어 개수]: 실제 각 단어에 대한 어텐선(attention) 값들\n",
    "        attention = attention.unsqueeze(1)\n",
    "        # attention: [배치 크기, 1, 단어 개수]: 실제 각 단어에 대한 어텐선(attention) 값들\n",
    "\n",
    "        enc_outputs = enc_outputs.permute(1, 0, 2)\n",
    "        # enc_outputs: [배치 크기, 단어 개수, 인코더 히든 차원 * 방향의 수]: 전체 단어의 출력 정보\n",
    "\n",
    "        weighted = torch.bmm(attention, enc_outputs) # 행렬 곱 함수\n",
    "        # weighted: [배치 크기, 1, 인코더 히든 차원 * 방향의 수]\n",
    "\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        # weighted: [1, 배치 크기, 인코더 히든 차원 * 방향의 수]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
    "        # rnn_input: [1, 배치 크기, 인코더 히든 차원 * 방향의 수 + embed_dim]: 어텐션이 적용된 현재 단어 입력 정보\n",
    "        \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        # output: [단어 개수, 배치 크기, 디코더 히든 차원 * 방향의 수]\n",
    "        # hidden: [레이어 개수 * 방향의 수, 배치 크기, 디코더 히든 차원]: 현재까지의 모든 단어의 정보\n",
    "\n",
    "        # 현재 예제에서는 단어 개수, 레이어 개수, 방향의 수 모두 1의 값을 가짐\n",
    "        # 따라서 output: [1, 배치 크기, 디코더 히든 차원], hidden: [1, 배치 크기, 디코더 히든 차원]\n",
    "        # 다시 말해 output과 hidden의 값 또한 동일\n",
    "        assert (output == hidden).all()\n",
    "\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
    "        # prediction = [배치 크기, 출력 차원]\n",
    "        \n",
    "        # (현재 출력 단어, 현재까지의 모든 단어의 정보)\n",
    "        return prediction, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    # 학습할 때는 완전한 형태의 소스 문장, 타겟 문장, teacher_forcing_ratio를 넣기\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src: [단어 개수, 배치 크기]\n",
    "        # trg: [단어 개수, 배치 크기]\n",
    "        # 먼저 인코더를 거쳐 전체 출력과 문맥 벡터(context vector)를 추출\n",
    "        enc_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        # 디코더(decoder)의 최종 결과를 담을 텐서 객체 만들기\n",
    "        trg_len = trg.shape[0] # 단어 개수\n",
    "        batch_size = trg.shape[1] # 배치 크기\n",
    "        trg_vocab_size = self.decoder.output_dim # 출력 차원\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        # 첫 번째 입력은 항상 <sos> 토큰\n",
    "        input = trg[0, :]\n",
    "\n",
    "        # 타겟 단어의 개수만큼 반복하여 디코더에 포워딩(forwarding)\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden, enc_outputs)\n",
    "\n",
    "            outputs[t] = output # FC를 거쳐서 나온 현재의 출력 단어 정보\n",
    "            top1 = output.argmax(1) # 가장 확률이 높은 단어의 인덱스 추출\n",
    "\n",
    "            # teacher_forcing_ratio: 학습할 때 실제 목표 출력(ground-truth)을 사용하는 비율\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            input = trg[t] if teacher_force else top1 # 현재의 출력 결과를 다음 입력에서 넣기\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENCODER_EMBED_DIM = 256\n",
    "DECODER_EMBED_DIM = 256\n",
    "ENCODER_HIDDEN_DIM = 512\n",
    "DECODER_HIDDEN_DIM = 512\n",
    "ENC_DROPOUT_RATIO = 0.5\n",
    "DEC_DROPOUT_RATIO = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션(attention) 객체 선언\n",
    "attn = Attention(ENCODER_HIDDEN_DIM, DECODER_HIDDEN_DIM)\n",
    "\n",
    "# 인코더(encoder)와 디코더(decoder) 객체 선언\n",
    "enc = Encoder(INPUT_DIM, ENCODER_EMBED_DIM, ENCODER_HIDDEN_DIM, DECODER_HIDDEN_DIM, ENC_DROPOUT_RATIO)\n",
    "dec = Decoder(OUTPUT_DIM, DECODER_EMBED_DIM, ENCODER_HIDDEN_DIM, DECODER_HIDDEN_DIM, DEC_DROPOUT_RATIO, attn)\n",
    "\n",
    "# Seq2Seq 객체 선언\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 가중치 파라미터 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7853, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 및 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer로 학습 최적화\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습(train) 함수\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train() # 학습 모드\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # 전체 학습 데이터를 확인하며\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "        # output: [출력 단어 개수, 배치 크기, 출력 차원]\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        # 출력 단어의 인덱스 0은 사용하지 않음\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(출력 단어의 개수 - 1) * batch size, output dim]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(타겟 단어의 개수 - 1) * batch size]\n",
    "        \n",
    "        # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward() # 기울기(gradient) 계산\n",
    "        \n",
    "        # 기울기(gradient) clipping 진행\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        # 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 전체 손실 값 계산\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가(evaluate) 함수\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval() # 평가 모드\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 전체 평가 데이터를 확인하며\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            # 평가할 때 teacher forcing는 사용하지 않음\n",
    "            output = model(src, trg, 0)\n",
    "            # output: [출력 단어 개수, 배치 크기, 출력 차원]\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            # 출력 단어의 인덱스 0은 사용하지 않음\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(출력 단어의 개수 - 1) * batch size, output dim]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(타겟 단어의 개수 - 1) * batch size]\n",
    "\n",
    "            # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            # 전체 손실 값 계산\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습(training) 및 검증(validation) 진행 학습 횟수(epoch): 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_loss : 훈련 손실값\n",
    "val_loss : 검증 손실값\n",
    "펄플렉서티(Perplexity, PPL) = 즉, PPL은 수치가 낮을수록 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 29s\n",
      "\tTrain Loss: 5.007 | Train PPL: 149.505\n",
      "\tValidation Loss: 4.929 | Validation PPL: 138.223\n",
      "Epoch: 02 | Time: 1m 28s\n",
      "\tTrain Loss: 4.099 | Train PPL: 60.283\n",
      "\tValidation Loss: 4.431 | Validation PPL: 83.981\n",
      "Epoch: 03 | Time: 1m 29s\n",
      "\tTrain Loss: 3.450 | Train PPL: 31.498\n",
      "\tValidation Loss: 3.696 | Validation PPL: 40.297\n",
      "Epoch: 04 | Time: 1m 29s\n",
      "\tTrain Loss: 2.911 | Train PPL: 18.376\n",
      "\tValidation Loss: 3.393 | Validation PPL: 29.770\n",
      "Epoch: 05 | Time: 1m 28s\n",
      "\tTrain Loss: 2.525 | Train PPL: 12.491\n",
      "\tValidation Loss: 3.277 | Validation PPL: 26.507\n",
      "Epoch: 06 | Time: 1m 28s\n",
      "\tTrain Loss: 2.222 | Train PPL: 9.225\n",
      "\tValidation Loss: 3.207 | Validation PPL: 24.710\n",
      "Epoch: 07 | Time: 1m 28s\n",
      "\tTrain Loss: 1.974 | Train PPL: 7.202\n",
      "\tValidation Loss: 3.182 | Validation PPL: 24.105\n",
      "Epoch: 08 | Time: 1m 29s\n",
      "\tTrain Loss: 1.750 | Train PPL: 5.757\n",
      "\tValidation Loss: 3.234 | Validation PPL: 25.381\n",
      "Epoch: 09 | Time: 1m 29s\n",
      "\tTrain Loss: 1.607 | Train PPL: 4.989\n",
      "\tValidation Loss: 3.240 | Validation PPL: 25.528\n",
      "Epoch: 10 | Time: 1m 29s\n",
      "\tTrain Loss: 1.472 | Train PPL: 4.358\n",
      "\tValidation Loss: 3.297 | Validation PPL: 27.039\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time() # 시작 시간 기록\n",
    "\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time() # 종료 시간 기록\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'seq2seq_with_attention.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
    "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.200 | Test PPL:  24.541 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('seq2seq_with_attention.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
