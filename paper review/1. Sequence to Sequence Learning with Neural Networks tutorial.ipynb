{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5cd494",
   "metadata": {},
   "source": [
    "# Sequence to Sequence Learning with Neural Networks (NIPS 2014) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2131012",
   "metadata": {},
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('https://youtu.be/VxR0sQUFKUc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c1d863",
   "metadata": {},
   "source": [
    "![Model structer](https://velog.velcdn.com/images%2Fxuio%2Fpost%2Fdd42208d-e3b1-4719-a198-c01efb6adc44%2F%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA%202022-01-28%20%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB%2011.05.09.png)\n",
    "\n",
    "- 'Sequence to Sequence는 하나의 Sequence에서 다른 Sequence로 번역을 진행 하겠다.'라는 것이다.\n",
    "\n",
    "기존에는 RNN기반의 번역을 진행하였는데 한계점이 많이 존재 했었다. 하지만 Sequence to Sequence의 논문이 나오면서 급격하게 딥러닝 기반 번역에 대한 기술이 많이 발전하게 되었고 Sequence to Sequence이후에 Attention과 transfomer 논문이 나오면서 현재는 transformer 가 state of the art로 사용되고 있는 상황이다.\n",
    "\n",
    "RNN 기반일 경우에는 입력 데이터와 출력 데이터의 크기가 같아야 번역이 가능했기에 짧은 문장은 번역이 가능했지만 긴 문장은 번역이 불가능 했었다. 하지만 Sequence to Sequence로 오면서 긴 문장도 번역이 가능해졌다.\n",
    "\n",
    "(RNN은 단어가 입력될 때 마다 hidden state가 바뀌지만 Sequence to Sequenc는 마지막 hidden state만 참고하는 것으로 알고있다.)\n",
    "\n",
    "sequence는 일반적으로 하나의 문장을 의미한다. 하나의 문장에는 여러개의 단어로 구성되어있고 각각의 단어를 토큰으로써 처리한다.\n",
    "\n",
    "(Encoder는 번역 전 문장 Sorce sentece Decoder는 번역 후 문장 Target sentece)\n",
    "\n",
    "이 Sequence to Sequence Learning with Neural Networks의 논문의 특징으로는 **고정된 벡터(Fiexed Vector)** 즉 Vector의 크기가 고정되어 있다는 점이다. 고정된 벡터에는 어떠한 문장의 정보를 모두 담아야 한다는 것이다.\n",
    "\n",
    "그렇기 때문에 고정된 크기 Vector에서 긴 문장만 입력되다가 짧은 문장이 나오면 효율이 감소하는 경우가 발생하게 된다.\n",
    "\n",
    "그리고 seq2seq의 아키텍처에 RNN을 적용하는것 보다 LSTM을 적용했을때 빈약적으로 성능이 향상 된것을 확인 할 수 있다. 또한 일반적인 방법으로 즉 reverse를 진행하지 않고 번역을 진행 했을때는 sorce sectece와 target sentece의 상응 하는 단어의 평균 distance멀어 'minimal time lag'이 발생하는데 reverse를 했을때 평균 distance가 변하지는 않지만 source language 안에 상응 하는 첫 몇몇의 단어가 target language의 첫 몇몇의 단어와 가까워져 'minimal time lag'가 매우 줄어 들었다는 것을 확인 할 수 있었다.\n",
    "\n",
    "딥러닝을 할때 임베딩(Embedding)을 하는 이유는 원-핫 인코딩(one-hot encoding)시 차원의 크기가 매우 커지기 때문에 작은 데이터로 표현될 수 있도록 임베딩 레이어를 이용한다.\n",
    "\n",
    "sos -> 시퀀스 시작을 알리기 위해\n",
    "\n",
    "eos -> 시퀀스 끝을 알리기 위해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea176d6",
   "metadata": {},
   "source": [
    "## 데이터 전처리(Preprocessing)\n",
    "\n",
    "- spacy 라이브러리: 문장의 토큰화(tokenization), 태깅(tagging) 등의 전처리 기능을 위한 라이브러리\n",
    "  - 영어(Engilsh)와 독일어(Deutsch) 전처리 모듈 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b469d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchtext.legacy.data import BucketIterator, Field\n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e41b33f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/conda/lib/python3.8/site-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.51.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.24.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.19.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting de-core-news-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.3.0/de_core_news_sm-3.3.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/conda/lib/python3.8/site-packages (from de-core-news-sm==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.24.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.7.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.6.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.19.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (4.51.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.9.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444d97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de_core_news_sm') # 영어 토큰화(tokenization)\n",
    "spacy_en = spacy.load('en_core_web_sm') # 독일어 토큰화(tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f642a71",
   "metadata": {},
   "source": [
    "- 영어(English) 및 독일어(Deuthsch) **토큰화 함수** 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff2421e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독일어(Deuthsch) 문장을 토큰화한 뒤에 순서를 뒤집는 함수\n",
    "def tokenize_de(text):\n",
    "    \n",
    "    return [token.text for token in spacy_de.tokenizer(text)][::-1]\n",
    "\n",
    "# 영어(English) 문장을 토큰화 하는 함수\n",
    "def tokenize_en(text):\n",
    "    return [token.text for token in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e33cc9a",
   "metadata": {},
   "source": [
    "- **필드(Field)** 라이브러리를 이용해 데이터세에 대한 구체적인 전처리 내용을 명시한다.\n",
    "- 번역 목표 = SRC(독일어), TRG(영어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76849ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize_de,init_token=\"<sos>\",eos_token=\"<eos>\",lower=True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize_en,init_token=\"<sos>\",eos_token=\"<eos>\",lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc404de1",
   "metadata": {},
   "source": [
    "- 대표적인 영어-독어 번역 데이터셋인  **Multi30k**를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c78fd0c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts= ('.de', '.en'),fields = (SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de3a0c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터셋(training dataset) 크기: 29000\n",
      "평가 데이터셋(validation dataset) 크기: 1014\n",
      "테스트 데이터셋(testing dataset) 크기: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"학습 데이터셋(training dataset) 크기: {len(train_data.examples)}\")\n",
    "print(f\"평가 데이터셋(validation dataset) 크기: {len(valid_data.examples)}\")\n",
    "print(f\"테스트 데이터셋(testing dataset) 크기: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b8f0887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['.', 'büsche', 'vieler', 'nähe', 'der', 'in', 'freien', 'im', 'sind', 'männer', 'weiße', 'junge', 'zwei'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1745f8a1",
   "metadata": {},
   "source": [
    "- **필드(Field)** 객체의 **build_vocab** 메서드를 이용해 영어와 독어의 단어 사전을 생성\n",
    "- **최소 2번이상** 등장한 단어만을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc628496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'steht', 'urinal', 'einem', 'an', 'kaffee', 'tasse', 'einer', 'mit', 'der', ',', 'mann', 'ein']\n",
      "['a', 'man', 'standing', 'at', 'a', 'urinal', 'with', 'a', 'coffee', 'cup', '.']\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 중 하나를 선택해 출력\n",
    "print(vars(train_data.examples[30])['src'])\n",
    "print(vars(train_data.examples[30])['trg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b28e2be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(SRC): 7853\n",
      "len(TRG): 5893\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq =2)\n",
    "TRG.build_vocab(train_data, min_freq =2)\n",
    "\n",
    "print(f\"len(SRC): {len(SRC.vocab)}\")\n",
    "print(f\"len(TRG): {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00ef051e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4112\n",
      "1752\n"
     ]
    }
   ],
   "source": [
    "print(TRG.vocab.stoi[\"abcbc\"])# 없는 단어 \n",
    "print(TRG.vocab.stoi[TRG.pad_token]) # 패딩(padding)\n",
    "print(TRG.vocab.stoi[\"<sos>\"]) # <sos>\n",
    "print(TRG.vocab.stoi[\"<eos>\"]) # <eos>\n",
    "print(TRG.vocab.stoi[\"hello\"])\n",
    "print(TRG.vocab.stoi[\"world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a4be4c",
   "metadata": {},
   "source": [
    "- 한 문장에 포함된 단어가 연속적으로 **LSTM**에 입력되어야 한다.\n",
    "  - 따라서 하나의 배치에 포함된 문장들이 가지는 단어의 개수가 유사하도록 만들면 좋다\n",
    "  - 이를 위해BucketIterator를 사용한다.\n",
    "  - **배치 크기(batch size): 128**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97a2bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "#일반적인 데이터 로더(data loader)의 iterator와 유사하게 사용가능\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f55446",
   "metadata": {},
   "source": [
    "## 인코더(Encoder)\n",
    "\n",
    "- 주어진 소스 문장을 **문맥 벡터(context vector)** 로 인코딩 한다.\n",
    "- LSTM은 hidden state과 cell state을 반환한다.\n",
    "- forward은 오직 hidden 과 sell을 반환\n",
    "- 하이버 파라미터(hyperparameter)\n",
    "  - **input_dim**: 하나의 단어에 대한 원핫 인코딩 차원\n",
    "  - **embed_dim**: 임베딩(embedding) 차원\n",
    "  - **hidden_dim**: 히든 상태(hidden state) 차원\n",
    "  - **n_layers**: RNN 레이어의 개수\n",
    "  - **dropout_ratio**: 드롭아웃(dropout) 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6bb4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 정의\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim, n_layers, dropout_ratio):\n",
    "        super().__init__()\n",
    "        \n",
    "        #임베딩은 원-핫 인코딩을 특정 차원의 임베딩으로 매핑하는 레이어\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
    "        \n",
    "        #LSTM 레이어\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers  = n_layers\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout = dropout_ratio)\n",
    "        \n",
    "        #드롭아웃(dropout)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "        \n",
    "    #인코더는 소스 문장을 입력으로 받아 문맥 벡터(context vector)를 반환\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded : [단어 개수, 배치 크기, 임베딩 차원]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        #outputs: [단어 개수, 배치 크기, 히든 차원] : 현재 단어의 출력 정보\n",
    "        #hidden: [레이어 개수, 배치 크기, 히든 차원]: 현재까지의 모든 단어의 정보\n",
    "        #cell: [레이어 개수, 배치 크기, 히든 차원]: 현재까지의 모든 단어의 정보\n",
    "        \n",
    "        #문맥 벡터(context vector)반환\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45845421",
   "metadata": {},
   "source": [
    "## 디코더(Decoder)\n",
    "\n",
    "- 주어진 문맥 백터(context vector)를 타켓 문장으로 디코딩 한다.\n",
    "- LSTM은 hidden state와 cell state를 반환한다.\n",
    "- 하이버 파라미터(hyperparameter)\n",
    "  - **input_dim**: 하나의 단어에 대한 원핫 인코딩 차원\n",
    "  - **embed_dim**: 임베딩(embedding) 차원\n",
    "  - **hidden_dim**: 히든 상태(hidden state) 차원\n",
    "  - **n_layers**: RNN 레이어의 개수\n",
    "  - **dropout_ratio**: 드롭아웃(dropout) 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eaaeba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 정의\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, hidden_dim, n_layers, dropout_ratio):\n",
    "        super().__init__()\n",
    "        \n",
    "        #임베딩은 원-핫 인코딩말고 특정 차원의 임베딩으로 매핑하는 레이어\n",
    "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
    "        \n",
    "        #LSTM 레이어\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout = dropout_ratio)\n",
    "        \n",
    "        #FC레이어 (인코더와 구조적으로 다른 부분)\n",
    "        self.output_dim = output_dim\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        #드롭아웃(dropout)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "        \n",
    "    # 디코더는 현재까지 출력된 문장에 대한 정보를 입력으로 받아 타켓 문장을 반환\n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input: [배치 크기]: 단어의 개수는 항상 1개이도록 구현\n",
    "        # hidden: [레이어 개수, 배치 크기, 히든 차원]\n",
    "        # cell = context: [레이어 개수, 배치 크기, 히든 차원]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input: [단어의 개수 = 1. 배치 크기]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        #embedded: [단어의 개수, 배치 크기. 임베딩 차원]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # output: [단어 개수 = 1, 배치 크기, 히든 차원]: 현재 단어의 출력 정보\n",
    "        # hidden: [레이어 개수, 배치 크기, 히든 차원]: 현재까지의 모든 단어의 정보\n",
    "        # cell: [레이어 개수, 배치 크기, 히든 차원]: 현재까지의 모든 단어의 정보\n",
    "        \n",
    "        #단어 개수는 어차피 1개이므로 차원 제거\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        #prediction = [배치 크기, 출력 차원]\n",
    "        \n",
    "        #(현재 출력 단어, 현재까지의 모든 단어의 정보, 현재까지의 모든 단어의 정보)\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fc447b",
   "metadata": {},
   "source": [
    "## seq2seq\n",
    "\n",
    "- 앞서 정의한 인코더()와 디코더()를 가지고 있는 하나의 아키텍처\n",
    "  - input/source sentece를 받는다.\n",
    "  - **인코더(encoder)**: 주어진 소스 문장을 문맥 벡터(context vector)로 인코딩 한다.\n",
    "  - **디코더(decoder)**: 주어진 문맥 벡터(context vector)를 타겟으로 디코딩 한다.\n",
    "  - 단, **디코더는 한 단어씩** 넣어서 한 번씩 결과를 구한다.\n",
    "  \n",
    "- **Teacher forcing**: 디코터의 예측을 다음 입력으로 사용하지 않고, 실제 목표 출력(ground-truth)을 다음 입력으로 사용하는 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "940986dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    #학습할 때는 완전한 형테의 소스 문장, 타겟 문장, teacher_forching_ratio를 넣기\n",
    "    def forward(self, src, trg, teacher_forcing_ratio= 0.5):\n",
    "        # src: [단어 개수, 배치 크기]\n",
    "        # trg: [단어 개수, 배치 크기]\n",
    "        # 먼저 인코더를 거쳐 문맥 벡터(context vector)를 추출\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        # 디코더(decoder)의 최종 결과를 담을 텐서 캑체 만들기\n",
    "        trg_len = trg.shape[0] # 단어의 갯수\n",
    "        batch_size = trg.shape[1] # 배치의 크기\n",
    "        trg_vocab_size = self.decoder.output_dim # 출력 차원\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # 첫 번째 입력은 항상 <sos> 토큰\n",
    "        input = trg[0, :]\n",
    "        \n",
    "        #타겟 단어의 개수만큼 반복하여 디코더에 포워딩(forwarding)\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            outputs[t] = output #FC를 거쳐서 나온 현재의 출력 단어 정보\n",
    "            top1 = output.argmax(1) # 가장 확률이 높은 단어의 인데스 추출\n",
    "            \n",
    "            # teacher_forcing_ratio: 학습할 때 실제 목표 출력(ground-truth)을 사용하는 비율\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            input = trg[t] if teacher_force else top1 # 현재의 출력 결과를 다음 입력에서 넣기\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e6f548",
   "metadata": {},
   "source": [
    "### 학습(Training)\n",
    "\n",
    " - 하이퍼 파라미터 설정 및 모델 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88f57324",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENCODER_EMBED_DIM = 256\n",
    "DECODER_EMBED_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "N_LAYERS =2\n",
    "ENC_DROPOUT_RATIO = 0.5\n",
    "DEC_DROPOUT_RATIO = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c121d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#인코더와 디코더 객체 선언\n",
    "enc = Encoder(INPUT_DIM, ENCODER_EMBED_DIM, HIDDEN_DIM, N_LAYERS, ENC_DROPOUT_RATIO)\n",
    "dec = Decoder(OUTPUT_DIM, DECODER_EMBED_DIM, HIDDEN_DIM, N_LAYERS, DEC_DROPOUT_RATIO)\n",
    "\n",
    "# Seq2Seq 객체 선언\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e60583",
   "metadata": {},
   "source": [
    "- 논문의 내용대로(−0.08,0.08)의 값을로 **모델 가중치 파라미터 초기화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e4f0d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7853, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7757e614",
   "metadata": {},
   "source": [
    "###  학습 및 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3761beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer로 학습 최적화\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5e04992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 13,898,501 trinable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trinable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e902c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 학습(train) 함수\n",
    "def train(model, iterator, optimizer, ctiterion, clip):\n",
    "    model.train() # 학습 모드\n",
    "    epoch_loss=0\n",
    "    \n",
    "    #전체 학습 데이터를 확인하며\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        # output: [출력 단어 개수, 배치 크기. 출력 차원]\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        # 출력 단어의 인덱스 0은 사용하지 않음\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        #output = [(출력 단어의 개수 -1) * batch size, output dim]\n",
    "        trg = trg[1:].view(-1)\n",
    "        #trg = [(타겟 단어의 개수 -1) * batch size]\n",
    "        \n",
    "        #모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward() # 기울기(gradient) 계산\n",
    "        \n",
    "        #기울기(gradient) clipping진행\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            \n",
    "        #파라미터 업데이트\n",
    "        optimizer.step()\n",
    "        \n",
    "        #전체 손실 값 계산\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d5ca1",
   "metadata": {},
   "source": [
    "with torch.no_grad(): block 안에서 기울기(graident)를 계산하지 않게 한다. 메모리 소비를 줄이고 스피드를 빠르게 해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6505e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가(evaluate) 함수\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval() #평가 모드 (dropout turn off)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        #전체 평가 데이터를 확인하며\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            \n",
    "            #평가할 때 teacher forcing는 사용하지 않음\n",
    "            output = model(src, trg, 0)\n",
    "            #output: [출력 단어 개수, 배치 크기. 출력 차원]\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            #출력 단어의 인덱스 0은 사용하지 않음\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            #output = [(출력 단어의 개수 -1) * batch size.output_dim]\n",
    "            trg = trg[1:].view(-1)\n",
    "            #trg = [(타겟 단어의 개수 -1) * batch size]\n",
    "            \n",
    "            #모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            #전체 손실 삾 계산\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2675a0",
   "metadata": {},
   "source": [
    "- 학습(training)및 검증(validation)진행\n",
    " - 학습 횟수(epoch): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c0f1ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_time * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babae2d5",
   "metadata": {},
   "source": [
    "펄플렉서티(Perplexity, PPL) = 모델 내에서 자신의 성능을 수치화하여 결과를 내놓는 것이다. 언어의 모델을 평가하기 위한 지표. 성능의 수치가 낮을수록 언어모델의 성능이 좋다는 것을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0feee5fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m -1574s\n",
      "\tTrain Loss: 5.054 | Train PPL: 156.688\n",
      "\tValidation Loss: 4.940 | Validation PPL: 139.759\n",
      "Epoch: 02 | Time: 0m -1590s\n",
      "\tTrain Loss: 4.500 | Train PPL: 90.021\n",
      "\tValidation Loss: 4.910 | Validation PPL: 135.604\n",
      "Epoch: 03 | Time: 0m -1453s\n",
      "\tTrain Loss: 4.256 | Train PPL: 70.532\n",
      "\tValidation Loss: 4.724 | Validation PPL: 112.595\n",
      "Epoch: 04 | Time: 0m -1442s\n",
      "\tTrain Loss: 4.025 | Train PPL: 55.973\n",
      "\tValidation Loss: 4.580 | Validation PPL: 97.543\n",
      "Epoch: 05 | Time: 0m -1531s\n",
      "\tTrain Loss: 3.880 | Train PPL: 48.432\n",
      "\tValidation Loss: 4.385 | Validation PPL: 80.218\n",
      "Epoch: 06 | Time: 0m -1545s\n",
      "\tTrain Loss: 3.744 | Train PPL: 42.260\n",
      "\tValidation Loss: 4.309 | Validation PPL: 74.389\n",
      "Epoch: 07 | Time: 0m -1516s\n",
      "\tTrain Loss: 3.619 | Train PPL: 37.318\n",
      "\tValidation Loss: 4.219 | Validation PPL: 67.990\n",
      "Epoch: 08 | Time: 0m -1553s\n",
      "\tTrain Loss: 3.498 | Train PPL: 33.057\n",
      "\tValidation Loss: 4.173 | Validation PPL: 64.930\n",
      "Epoch: 09 | Time: 0m -1562s\n",
      "\tTrain Loss: 3.384 | Train PPL: 29.488\n",
      "\tValidation Loss: 4.020 | Validation PPL: 55.682\n",
      "Epoch: 10 | Time: 0m -1446s\n",
      "\tTrain Loss: 3.262 | Train PPL: 26.114\n",
      "\tValidation Loss: 4.054 | Validation PPL: 57.624\n",
      "Epoch: 11 | Time: 0m -1534s\n",
      "\tTrain Loss: 3.159 | Train PPL: 23.553\n",
      "\tValidation Loss: 3.929 | Validation PPL: 50.835\n",
      "Epoch: 12 | Time: 0m -1557s\n",
      "\tTrain Loss: 3.066 | Train PPL: 21.456\n",
      "\tValidation Loss: 4.043 | Validation PPL: 57.006\n",
      "Epoch: 13 | Time: 0m -1442s\n",
      "\tTrain Loss: 3.004 | Train PPL: 20.171\n",
      "\tValidation Loss: 3.895 | Validation PPL: 49.133\n",
      "Epoch: 14 | Time: 0m -1559s\n",
      "\tTrain Loss: 2.900 | Train PPL: 18.176\n",
      "\tValidation Loss: 3.878 | Validation PPL: 48.345\n",
      "Epoch: 15 | Time: 0m -1427s\n",
      "\tTrain Loss: 2.806 | Train PPL: 16.539\n",
      "\tValidation Loss: 3.889 | Validation PPL: 48.862\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 15\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time() # 시작 시간 기록\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time() # 종료 시간 기록\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'seq2seq.pt')\n",
    "        \n",
    "        \n",
    "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
    "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2f4c434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.905 | Test PPL:  49.655 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('seq2seq.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba270d",
   "metadata": {},
   "source": [
    "## 나만의 데이터로 모델 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a87aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#번역 함수\n",
    "def translate_sentence(sentence, src_field, trg_field, model, divice, max_len_50):\n",
    "    model,eval()#평가모드\n",
    "    \n",
    "    if isinstance(sentecnem, str):\n",
    "        nip = spacy.load('de')\n",
    "        tokens = [token.text.lower() for token in nlp(sentecve)]\n",
    "    else:\n",
    "        toekns = [token.lower() for token in sentence]\n",
    "        \n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "    print(f\"전체 소스 토큰: {tokens}\")\n",
    "    \n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(src_tensor)\n",
    "        \n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        \n",
    "        trg_tensor =torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
    "        \n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes,append(pred_token)\n",
    "        \n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "        \n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d4a6984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소스 문장: ['.', 'freien', 'im', 'tag', 'schönen', 'einen', 'genießen', 'sohn', 'kleiner', 'ihr', 'und', 'mutter', 'eine']\n",
      "타겟 문장: ['a', 'mother', 'and', 'her', 'young', 'song', 'enjoying', 'a', 'beautiful', 'day', 'outside', '.']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 10\n",
    "\n",
    "src = vars(test_data.examples[example_idx])['src']\n",
    "trg = vars(test_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'소스 문장: {src}')\n",
    "print(f'타겟 문장: {trg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57d00f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소스 문장: ['.', 'Abend', 'Guten']\n"
     ]
    }
   ],
   "source": [
    "src = tokenize_de(\"Guten Abend.\")\n",
    "\n",
    "print(f'소스 문장: {src}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
